{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Scikit-Learn Algorithms from Scratch\n",
    "\n",
    "This notebook covers implementing classic machine learning algorithms from scratch, commonly asked in ML engineering interviews.\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "1. [K-Means Clustering](#k-means-clustering)\n",
    "2. [Logistic Regression with Regularization](#logistic-regression)\n",
    "3. [Decision Tree Implementation](#decision-tree)\n",
    "4. [Model Evaluation and Cross-Validation](#model-evaluation)\n",
    "5. [Practice Problems](#practice-problems)\n",
    "6. [Interview Tips](#interview-tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_blobs, load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"ðŸ“Š NumPy version: {np.__version__}\")\n",
    "print(f\"ðŸ¤– Scikit-learn available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Problem 1: K-Means Clustering from Scratch\n",
    "\n",
    "**Problem Statement**: Implement K-means clustering algorithm using Lloyd's algorithm.\n",
    "\n",
    "**Requirements**:\n",
    "- Initialize centroids randomly or using K-means++\n",
    "- Implement Lloyd's algorithm with convergence criteria\n",
    "- Calculate within-cluster sum of squares (WCSS)\n",
    "- Handle edge cases (empty clusters, convergence)\n",
    "\n",
    "**Time Complexity**: O(n Ã— k Ã— i Ã— d) where n=samples, k=clusters, i=iterations, d=dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansFromScratch:\n",
    "    \"\"\"K-means clustering implementation from scratch.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_clusters=3, max_iters=100, tol=1e-4, init='random'):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iters = max_iters\n",
    "        self.tol = tol\n",
    "        self.init = init  # 'random' or 'kmeans++'\n",
    "        \n",
    "    def _initialize_centroids(self, X):\n",
    "        \"\"\"Initialize centroids using random or K-means++ method.\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        if self.init == 'random':\n",
    "            # Random initialization\n",
    "            indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "            centroids = X[indices].copy()\n",
    "        \n",
    "        elif self.init == 'kmeans++':\n",
    "            # K-means++ initialization\n",
    "            centroids = np.zeros((self.n_clusters, n_features))\n",
    "            \n",
    "            # Choose first centroid randomly\n",
    "            centroids[0] = X[np.random.randint(n_samples)]\n",
    "            \n",
    "            for i in range(1, self.n_clusters):\n",
    "                # Calculate distances to nearest centroid\n",
    "                distances = np.array([min([np.linalg.norm(x - c) ** 2 \n",
    "                                         for c in centroids[:i]]) for x in X])\n",
    "                \n",
    "                # Choose next centroid with probability proportional to squared distance\n",
    "                probabilities = distances / distances.sum()\n",
    "                cumulative_probabilities = probabilities.cumsum()\n",
    "                r = np.random.rand()\n",
    "                \n",
    "                for j, p in enumerate(cumulative_probabilities):\n",
    "                    if r < p:\n",
    "                        centroids[i] = X[j]\n",
    "                        break\n",
    "        \n",
    "        return centroids\n",
    "    \n",
    "    def _assign_clusters(self, X, centroids):\n",
    "        \"\"\"Assign each point to the nearest centroid.\"\"\"\n",
    "        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        return np.argmin(distances, axis=0)\n",
    "    \n",
    "    def _update_centroids(self, X, labels):\n",
    "        \"\"\"Update centroids based on current assignments.\"\"\"\n",
    "        centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "        \n",
    "        for k in range(self.n_clusters):\n",
    "            if np.sum(labels == k) > 0:\n",
    "                centroids[k] = X[labels == k].mean(axis=0)\n",
    "            else:\n",
    "                # Handle empty cluster by reinitializing\n",
    "                centroids[k] = X[np.random.randint(len(X))]\n",
    "        \n",
    "        return centroids\n",
    "    \n",
    "    def _calculate_wcss(self, X, labels, centroids):\n",
    "        \"\"\"Calculate Within-Cluster Sum of Squares.\"\"\"\n",
    "        wcss = 0\n",
    "        for k in range(self.n_clusters):\n",
    "            cluster_points = X[labels == k]\n",
    "            if len(cluster_points) > 0:\n",
    "                wcss += np.sum((cluster_points - centroids[k]) ** 2)\n",
    "        return wcss\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit K-means clustering to data.\"\"\"\n",
    "        # Initialize centroids\n",
    "        self.centroids = self._initialize_centroids(X)\n",
    "        self.wcss_history = []\n",
    "        \n",
    "        for iteration in range(self.max_iters):\n",
    "            # Assign points to clusters\n",
    "            self.labels = self._assign_clusters(X, self.centroids)\n",
    "            \n",
    "            # Calculate WCSS\n",
    "            wcss = self._calculate_wcss(X, self.labels, self.centroids)\n",
    "            self.wcss_history.append(wcss)\n",
    "            \n",
    "            # Update centroids\n",
    "            new_centroids = self._update_centroids(X, self.labels)\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.allclose(self.centroids, new_centroids, rtol=self.tol):\n",
    "                print(f\"Converged after {iteration + 1} iterations\")\n",
    "                break\n",
    "                \n",
    "            self.centroids = new_centroids\n",
    "        \n",
    "        # Final WCSS calculation\n",
    "        self.inertia_ = self._calculate_wcss(X, self.labels, self.centroids)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict cluster labels for new data.\"\"\"\n",
    "        return self._assign_clusters(X, self.centroids)\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"Fit the model and predict cluster labels.\"\"\"\n",
    "        return self.fit(X).labels\n",
    "\n",
    "# Test K-means implementation\n",
    "print(\"ðŸ§ª Testing K-Means Implementation:\")\n",
    "\n",
    "# Generate sample data\n",
    "X_blobs, y_true = make_blobs(n_samples=300, centers=4, n_features=2, \n",
    "                            random_state=42, cluster_std=0.60)\n",
    "\n",
    "# Apply our K-means\n",
    "kmeans_custom = KMeansFromScratch(n_clusters=4, init='kmeans++', max_iters=100)\n",
    "labels_custom = kmeans_custom.fit_predict(X_blobs)\n",
    "\n",
    "print(f\"Final WCSS: {kmeans_custom.inertia_:.2f}\")\n",
    "print(f\"Number of iterations: {len(kmeans_custom.wcss_history)}\")\n",
    "\n",
    "# Compare with sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans_sklearn = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "labels_sklearn = kmeans_sklearn.fit_predict(X_blobs)\n",
    "\n",
    "print(f\"Sklearn WCSS: {kmeans_sklearn.inertia_:.2f}\")\n",
    "print(f\"\\nCustom implementation WCSS: {kmeans_custom.inertia_:.2f}\")\n",
    "print(f\"Difference: {abs(kmeans_sklearn.inertia_ - kmeans_custom.inertia_):.2f}\")\n",
    "\n",
    "print(\"\\nâœ… K-means implementation test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize K-means results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Original data with true clusters\n",
    "plt.subplot(1, 3, 1)\n",
    "scatter = plt.scatter(X_blobs[:, 0], X_blobs[:, 1], c=y_true, alpha=0.7)\n",
    "plt.title('True Clusters')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(scatter)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Our K-means results\n",
    "plt.subplot(1, 3, 2)\n",
    "scatter = plt.scatter(X_blobs[:, 0], X_blobs[:, 1], c=labels_custom, alpha=0.7)\n",
    "plt.scatter(kmeans_custom.centroids[:, 0], kmeans_custom.centroids[:, 1], \n",
    "           c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "plt.title('Custom K-means Results')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.colorbar(scatter)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: WCSS convergence\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(1, len(kmeans_custom.wcss_history) + 1), \n",
    "         kmeans_custom.wcss_history, 'o-', alpha=0.8)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Within-Cluster Sum of Squares')\n",
    "plt.title('WCSS Convergence')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Elbow method for optimal K\n",
    "def elbow_method(X, max_k=10):\n",
    "    \"\"\"Find optimal number of clusters using elbow method.\"\"\"\n",
    "    wcss_values = []\n",
    "    k_values = range(1, max_k + 1)\n",
    "    \n",
    "    for k in k_values:\n",
    "        if k == 1:\n",
    "            # For k=1, WCSS is total sum of squares from the mean\n",
    "            center = X.mean(axis=0)\n",
    "            wcss = np.sum((X - center) ** 2)\n",
    "        else:\n",
    "            kmeans = KMeansFromScratch(n_clusters=k, max_iters=50)\n",
    "            kmeans.fit(X)\n",
    "            wcss = kmeans.inertia_\n",
    "        \n",
    "        wcss_values.append(wcss)\n",
    "    \n",
    "    return k_values, wcss_values\n",
    "\n",
    "# Run elbow method\n",
    "print(\"ðŸ§ª Running Elbow Method Analysis:\")\n",
    "k_range, wcss_values = elbow_method(X_blobs, max_k=8)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, wcss_values, 'o-', linewidth=2, markersize=8, alpha=0.8)\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Within-Cluster Sum of Squares')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight the elbow point (k=4 in this case)\n",
    "plt.axvline(x=4, color='red', linestyle='--', alpha=0.7, label='Optimal k=4')\n",
    "plt.legend()\n",
    "\n",
    "# Add annotations\n",
    "for k, wcss in zip(k_range, wcss_values):\n",
    "    plt.annotate(f'{wcss:.0f}', (k, wcss), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', fontsize=9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"WCSS values: {[f'{w:.1f}' for w in wcss_values]}\")\n",
    "print(\"ðŸŽ¯ Optimal k appears to be 4 (elbow point)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Problem 2: Logistic Regression with Regularization\n",
    "\n",
    "**Problem Statement**: Implement logistic regression with L1/L2 regularization and multiple solvers.\n",
    "\n",
    "**Requirements**:\n",
    "- Binary and multiclass classification support\n",
    "- L1 (Lasso) and L2 (Ridge) regularization\n",
    "- Gradient descent with different optimizers\n",
    "- Probability predictions and decision boundaries\n",
    "- Handle numerical stability issues\n",
    "\n",
    "**Key Concepts**: Sigmoid function, cross-entropy loss, gradient descent, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionFromScratch:\n",
    "    \"\"\"Logistic Regression with regularization from scratch.\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, max_iters=1000, \n",
    "                 regularization=None, reg_strength=0.01,\n",
    "                 fit_intercept=True, tol=1e-6, solver='gd'):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iters = max_iters\n",
    "        self.regularization = regularization  # None, 'l1', 'l2', 'elasticnet'\n",
    "        self.reg_strength = reg_strength\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.tol = tol\n",
    "        self.solver = solver  # 'gd', 'sgd', 'adam'\n",
    "        \n",
    "        # For Adam optimizer\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        \n",
    "    def _add_intercept(self, X):\n",
    "        \"\"\"Add bias term to features.\"\"\"\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Sigmoid activation with numerical stability.\"\"\"\n",
    "        # Clip z to prevent overflow\n",
    "        z = np.clip(z, -250, 250)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def _cost_function(self, X, y, weights):\n",
    "        \"\"\"Calculate logistic regression cost with regularization.\"\"\"\n",
    "        # Forward pass\n",
    "        z = X @ weights\n",
    "        predictions = self._sigmoid(z)\n",
    "        \n",
    "        # Avoid log(0) by adding small epsilon\n",
    "        epsilon = 1e-15\n",
    "        predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "        \n",
    "        # Binary cross-entropy loss\n",
    "        cost = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "        \n",
    "        # Add regularization\n",
    "        if self.regularization == 'l1':\n",
    "            # Don't regularize intercept\n",
    "            reg_weights = weights[1:] if self.fit_intercept else weights\n",
    "            cost += self.reg_strength * np.sum(np.abs(reg_weights))\n",
    "        elif self.regularization == 'l2':\n",
    "            reg_weights = weights[1:] if self.fit_intercept else weights\n",
    "            cost += self.reg_strength * np.sum(reg_weights ** 2)\n",
    "        elif self.regularization == 'elasticnet':\n",
    "            reg_weights = weights[1:] if self.fit_intercept else weights\n",
    "            l1_penalty = self.reg_strength * 0.5 * np.sum(np.abs(reg_weights))\n",
    "            l2_penalty = self.reg_strength * 0.5 * np.sum(reg_weights ** 2)\n",
    "            cost += l1_penalty + l2_penalty\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    def _compute_gradients(self, X, y, weights):\n",
    "        \"\"\"Compute gradients for weight updates.\"\"\"\n",
    "        # Forward pass\n",
    "        z = X @ weights\n",
    "        predictions = self._sigmoid(z)\n",
    "        \n",
    "        # Basic gradient\n",
    "        gradients = (1 / len(y)) * X.T @ (predictions - y)\n",
    "        \n",
    "        # Add regularization gradients\n",
    "        if self.regularization == 'l1':\n",
    "            l1_grad = self.reg_strength * np.sign(weights)\n",
    "            if self.fit_intercept:\n",
    "                l1_grad[0] = 0  # Don't regularize intercept\n",
    "            gradients += l1_grad\n",
    "        elif self.regularization == 'l2':\n",
    "            l2_grad = 2 * self.reg_strength * weights\n",
    "            if self.fit_intercept:\n",
    "                l2_grad[0] = 0  # Don't regularize intercept\n",
    "            gradients += l2_grad\n",
    "        elif self.regularization == 'elasticnet':\n",
    "            l1_grad = self.reg_strength * 0.5 * np.sign(weights)\n",
    "            l2_grad = self.reg_strength * 0.5 * 2 * weights\n",
    "            if self.fit_intercept:\n",
    "                l1_grad[0] = 0\n",
    "                l2_grad[0] = 0\n",
    "            gradients += l1_grad + l2_grad\n",
    "        \n",
    "        return gradients\n",
    "    \n",
    "    def _update_weights_gd(self, gradients):\n",
    "        \"\"\"Standard gradient descent update.\"\"\"\n",
    "        self.weights -= self.learning_rate * gradients\n",
    "    \n",
    "    def _update_weights_adam(self, gradients, t):\n",
    "        \"\"\"Adam optimizer update.\"\"\"\n",
    "        # Update biased first moment estimate\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * gradients\n",
    "        \n",
    "        # Update biased second raw moment estimate\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (gradients ** 2)\n",
    "        \n",
    "        # Compute bias-corrected first moment estimate\n",
    "        m_corrected = self.m / (1 - self.beta1 ** t)\n",
    "        \n",
    "        # Compute bias-corrected second raw moment estimate\n",
    "        v_corrected = self.v / (1 - self.beta2 ** t)\n",
    "        \n",
    "        # Update weights\n",
    "        self.weights -= self.learning_rate * m_corrected / (np.sqrt(v_corrected) + self.epsilon)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the logistic regression model.\"\"\"\n",
    "        # Add intercept term if needed\n",
    "        if self.fit_intercept:\n",
    "            X = self._add_intercept(X)\n",
    "        \n",
    "        # Initialize weights\n",
    "        n_features = X.shape[1]\n",
    "        self.weights = np.random.normal(0, 0.01, n_features)\n",
    "        \n",
    "        # Initialize Adam optimizer variables\n",
    "        if self.solver == 'adam':\n",
    "            self.m = np.zeros_like(self.weights)\n",
    "            self.v = np.zeros_like(self.weights)\n",
    "        \n",
    "        # Store training history\n",
    "        self.cost_history = []\n",
    "        \n",
    "        # Training loop\n",
    "        for i in range(self.max_iters):\n",
    "            # Calculate cost\n",
    "            cost = self._cost_function(X, y, self.weights)\n",
    "            self.cost_history.append(cost)\n",
    "            \n",
    "            # Compute gradients\n",
    "            gradients = self._compute_gradients(X, y, self.weights)\n",
    "            \n",
    "            # Update weights based on solver\n",
    "            if self.solver == 'gd':\n",
    "                self._update_weights_gd(gradients)\n",
    "            elif self.solver == 'adam':\n",
    "                self._update_weights_adam(gradients, i + 1)\n",
    "            elif self.solver == 'sgd':\n",
    "                # Simple SGD implementation\n",
    "                indices = np.random.choice(len(X), size=min(32, len(X)), replace=False)\n",
    "                X_batch = X[indices]\n",
    "                y_batch = y[indices]\n",
    "                batch_gradients = self._compute_gradients(X_batch, y_batch, self.weights)\n",
    "                self._update_weights_gd(batch_gradients)\n",
    "            \n",
    "            # Check for convergence\n",
    "            if i > 0 and abs(self.cost_history[-2] - self.cost_history[-1]) < self.tol:\n",
    "                print(f\"Converged after {i + 1} iterations\")\n",
    "                break\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities.\"\"\"\n",
    "        if self.fit_intercept:\n",
    "            X = self._add_intercept(X)\n",
    "        \n",
    "        return self._sigmoid(X @ self.weights)\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"Predict binary class labels.\"\"\"\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return (probabilities >= threshold).astype(int)\n",
    "\n",
    "# Test Logistic Regression implementation\n",
    "print(\"ðŸ§ª Testing Logistic Regression Implementation:\")\n",
    "\n",
    "# Generate sample data\n",
    "X_class, y_class = make_classification(n_samples=1000, n_features=2, n_redundant=0,\n",
    "                                      n_informative=2, n_clusters_per_class=1, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# Test different configurations\n",
    "configs = [\n",
    "    {'regularization': None, 'solver': 'gd', 'name': 'No Regularization (GD)'},\n",
    "    {'regularization': 'l2', 'reg_strength': 0.01, 'solver': 'gd', 'name': 'L2 Regularization (GD)'},\n",
    "    {'regularization': 'l1', 'reg_strength': 0.01, 'solver': 'gd', 'name': 'L1 Regularization (GD)'},\n",
    "    {'regularization': 'l2', 'reg_strength': 0.01, 'solver': 'adam', 'name': 'L2 Regularization (Adam)'}\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\n=== Testing {config['name']} ===\")\n",
    "    \n",
    "    # Create and train model\n",
    "    lr = LogisticRegressionFromScratch(\n",
    "        learning_rate=0.01,\n",
    "        max_iters=1000,\n",
    "        regularization=config.get('regularization'),\n",
    "        reg_strength=config.get('reg_strength', 0.01),\n",
    "        solver=config.get('solver', 'gd')\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    lr.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = lr.predict(X_test)\n",
    "    y_proba = lr.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'name': config['name'],\n",
    "        'accuracy': accuracy,\n",
    "        'final_cost': lr.cost_history[-1],\n",
    "        'iterations': len(lr.cost_history),\n",
    "        'training_time': training_time,\n",
    "        'weights': lr.weights.copy(),\n",
    "        'cost_history': lr.cost_history.copy()\n",
    "    })\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Final cost: {lr.cost_history[-1]:.4f}\")\n",
    "    print(f\"Training time: {training_time:.3f}s\")\n",
    "    print(f\"Iterations: {len(lr.cost_history)}\")\n",
    "\n",
    "print(\"\\nâœ… Logistic Regression tests completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Logistic Regression results\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Original data\n",
    "plt.subplot(3, 3, 1)\n",
    "scatter = plt.scatter(X_class[:, 0], X_class[:, 1], c=y_class, alpha=0.7)\n",
    "plt.title('Training Data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(scatter)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2-5: Decision boundaries for different models\n",
    "def plot_decision_boundary(X, y, model, title, subplot_idx):\n",
    "    plt.subplot(3, 3, subplot_idx)\n",
    "    \n",
    "    # Create a mesh\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Predict on mesh\n",
    "    mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = model.predict_proba(mesh_points)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    plt.contourf(xx, yy, Z, levels=50, alpha=0.6, cmap='RdYlBu')\n",
    "    plt.contour(xx, yy, Z, levels=[0.5], colors='black', linestyles='--', linewidths=2)\n",
    "    \n",
    "    # Plot data points\n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.8, edgecolors='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "\n",
    "# Plot decision boundaries for first 4 models\n",
    "for i, result in enumerate(results[:4]):\n",
    "    # Recreate model with learned weights\n",
    "    model = LogisticRegressionFromScratch()\n",
    "    model.weights = result['weights']\n",
    "    model.fit_intercept = True\n",
    "    \n",
    "    plot_decision_boundary(X_test, y_test, model, result['name'], i + 2)\n",
    "\n",
    "# Plot 6: Cost histories\n",
    "plt.subplot(3, 3, 6)\n",
    "for result in results:\n",
    "    plt.plot(result['cost_history'], label=result['name'], alpha=0.8)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Training Cost History')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 7: Accuracy comparison\n",
    "plt.subplot(3, 3, 7)\n",
    "names = [r['name'] for r in results]\n",
    "accuracies = [r['accuracy'] for r in results]\n",
    "bars = plt.bar(range(len(names)), accuracies, alpha=0.7)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(range(len(names)), [n.split('(')[0][:10] + '...' for n in names], rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 8: Training time comparison\n",
    "plt.subplot(3, 3, 8)\n",
    "times = [r['training_time'] for r in results]\n",
    "bars = plt.bar(range(len(names)), times, alpha=0.7, color='orange')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Training Time (s)')\n",
    "plt.title('Training Time Comparison')\n",
    "plt.xticks(range(len(names)), [n.split('(')[0][:10] + '...' for n in names], rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, time_val in zip(bars, times):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.05,\n",
    "             f'{time_val:.3f}s', ha='center', va='bottom')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 9: Weight magnitudes (regularization effect)\n",
    "plt.subplot(3, 3, 9)\n",
    "for i, result in enumerate(results):\n",
    "    weights = result['weights']\n",
    "    weight_magnitudes = np.abs(weights[1:])  # Exclude intercept\n",
    "    plt.bar(np.arange(len(weight_magnitudes)) + i*0.2, weight_magnitudes, \n",
    "            width=0.2, label=result['name'].split('(')[0][:10], alpha=0.7)\n",
    "\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Weight Magnitude')\n",
    "plt.title('Weight Magnitudes (Regularization Effect)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"ðŸ“Š Model Performance Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Model':<25} {'Accuracy':<12} {'Final Cost':<12} {'Time (s)':<10} {'Iterations':<12}\")\n",
    "print(\"=\" * 80)\n",
    "for result in results:\n",
    "    print(f\"{result['name'][:24]:<25} {result['accuracy']:<12.4f} \"\n",
    "          f\"{result['final_cost']:<12.4f} {result['training_time']:<10.3f} {result['iterations']:<12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ³ Problem 3: Decision Tree Implementation\n",
    "\n",
    "**Problem Statement**: Implement a decision tree classifier with different splitting criteria.\n",
    "\n",
    "**Requirements**:\n",
    "- Support for Gini impurity, Entropy, and Classification Error\n",
    "- Recursive tree building with stopping criteria\n",
    "- Handle categorical and numerical features\n",
    "- Pruning to prevent overfitting\n",
    "- Visualization of the tree structure\n",
    "\n",
    "**Key Concepts**: Information gain, impurity measures, recursive partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode:\n",
    "    \"\"\"Node class for decision tree.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.value = None  # For leaf nodes\n",
    "        self.samples = 0\n",
    "        self.impurity = 0\n",
    "\n",
    "class DecisionTreeFromScratch:\n",
    "    \"\"\"Decision Tree Classifier implementation from scratch.\"\"\"\n",
    "    \n",
    "    def __init__(self, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                 min_samples_leaf=1, max_features=None):\n",
    "        self.criterion = criterion  # 'gini', 'entropy', 'misclassification'\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.root = None\n",
    "        self.n_classes_ = None\n",
    "        self.n_features_ = None\n",
    "    \n",
    "    def _calculate_impurity(self, y):\n",
    "        \"\"\"Calculate impurity based on criterion.\"\"\"\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        \n",
    "        proportions = np.bincount(y) / len(y)\n",
    "        \n",
    "        if self.criterion == 'gini':\n",
    "            return 1 - np.sum(proportions ** 2)\n",
    "        elif self.criterion == 'entropy':\n",
    "            # Avoid log(0)\n",
    "            proportions = proportions[proportions > 0]\n",
    "            return -np.sum(proportions * np.log2(proportions))\n",
    "        elif self.criterion == 'misclassification':\n",
    "            return 1 - np.max(proportions)\n",
    "    \n",
    "    def _calculate_information_gain(self, y, left_indices, right_indices):\n",
    "        \"\"\"Calculate information gain from a split.\"\"\"\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_indices), len(right_indices)\n",
    "        \n",
    "        if n_left == 0 or n_right == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Parent impurity\n",
    "        parent_impurity = self._calculate_impurity(y)\n",
    "        \n",
    "        # Children impurities\n",
    "        left_impurity = self._calculate_impurity(y[left_indices])\n",
    "        right_impurity = self._calculate_impurity(y[right_indices])\n",
    "        \n",
    "        # Weighted average of children impurities\n",
    "        weighted_impurity = (n_left / n) * left_impurity + (n_right / n) * right_impurity\n",
    "        \n",
    "        return parent_impurity - weighted_impurity\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        \"\"\"Find the best feature and threshold to split on.\"\"\"\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        \n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Feature selection\n",
    "        if self.max_features is None:\n",
    "            features_to_consider = range(n_features)\n",
    "        else:\n",
    "            n_features_to_consider = min(self.max_features, n_features)\n",
    "            features_to_consider = np.random.choice(n_features, n_features_to_consider, replace=False)\n",
    "        \n",
    "        for feature_index in features_to_consider:\n",
    "            feature_values = X[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            \n",
    "            for threshold in possible_thresholds:\n",
    "                left_indices = np.where(feature_values <= threshold)[0]\n",
    "                right_indices = np.where(feature_values > threshold)[0]\n",
    "                \n",
    "                # Check minimum samples constraints\n",
    "                if (len(left_indices) < self.min_samples_leaf or \n",
    "                    len(right_indices) < self.min_samples_leaf):\n",
    "                    continue\n",
    "                \n",
    "                # Calculate information gain\n",
    "                gain = self._calculate_information_gain(y, left_indices, right_indices)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold, best_gain\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        \"\"\"Recursively build the decision tree.\"\"\"\n",
    "        node = DecisionTreeNode()\n",
    "        node.samples = len(y)\n",
    "        node.impurity = self._calculate_impurity(y)\n",
    "        \n",
    "        # Stopping criteria\n",
    "        if (len(y) < self.min_samples_split or \n",
    "            (self.max_depth is not None and depth >= self.max_depth) or\n",
    "            len(np.unique(y)) == 1):  # Pure node\n",
    "            \n",
    "            # Create leaf node\n",
    "            node.value = np.argmax(np.bincount(y))\n",
    "            return node\n",
    "        \n",
    "        # Find best split\n",
    "        best_feature, best_threshold, best_gain = self._find_best_split(X, y)\n",
    "        \n",
    "        if best_feature is None or best_gain <= 0:\n",
    "            # No good split found, create leaf\n",
    "            node.value = np.argmax(np.bincount(y))\n",
    "            return node\n",
    "        \n",
    "        # Create internal node\n",
    "        node.feature_index = best_feature\n",
    "        node.threshold = best_threshold\n",
    "        \n",
    "        # Split data\n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = ~left_indices\n",
    "        \n",
    "        # Recursively build children\n",
    "        node.left = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        node.right = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the decision tree.\"\"\"\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        \n",
    "        # Build the tree\n",
    "        self.root = self._build_tree(X, y)\n",
    "        return self\n",
    "    \n",
    "    def _predict_sample(self, x, node):\n",
    "        \"\"\"Predict a single sample.\"\"\"\n",
    "        if node.value is not None:  # Leaf node\n",
    "            return node.value\n",
    "        \n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self._predict_sample(x, node.right)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for samples.\"\"\"\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            predictions.append(self._predict_sample(x, self.root))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def _get_tree_depth(self, node):\n",
    "        \"\"\"Calculate the depth of the tree.\"\"\"\n",
    "        if node.value is not None:  # Leaf node\n",
    "            return 1\n",
    "        \n",
    "        left_depth = self._get_tree_depth(node.left) if node.left else 0\n",
    "        right_depth = self._get_tree_depth(node.right) if node.right else 0\n",
    "        \n",
    "        return 1 + max(left_depth, right_depth)\n",
    "    \n",
    "    def get_tree_depth(self):\n",
    "        \"\"\"Get the depth of the fitted tree.\"\"\"\n",
    "        return self._get_tree_depth(self.root)\n",
    "    \n",
    "    def _count_nodes(self, node):\n",
    "        \"\"\"Count total number of nodes in the tree.\"\"\"\n",
    "        if node.value is not None:  # Leaf node\n",
    "            return 1\n",
    "        \n",
    "        left_count = self._count_nodes(node.left) if node.left else 0\n",
    "        right_count = self._count_nodes(node.right) if node.right else 0\n",
    "        \n",
    "        return 1 + left_count + right_count\n",
    "    \n",
    "    def count_nodes(self):\n",
    "        \"\"\"Count total number of nodes in the fitted tree.\"\"\"\n",
    "        return self._count_nodes(self.root)\n",
    "\n",
    "# Test Decision Tree implementation\n",
    "print(\"ðŸ§ª Testing Decision Tree Implementation:\")\n",
    "\n",
    "# Load Iris dataset for testing\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.3, random_state=42)\n",
    "\n",
    "# Test different criteria\n",
    "criteria = ['gini', 'entropy', 'misclassification']\n",
    "dt_results = []\n",
    "\n",
    "for criterion in criteria:\n",
    "    print(f\"\\n=== Testing with {criterion} criterion ===\")\n",
    "    \n",
    "    # Create and train decision tree\n",
    "    dt = DecisionTreeFromScratch(\n",
    "        criterion=criterion,\n",
    "        max_depth=5,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    dt.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    tree_depth = dt.get_tree_depth()\n",
    "    node_count = dt.count_nodes()\n",
    "    \n",
    "    dt_results.append({\n",
    "        'criterion': criterion,\n",
    "        'accuracy': accuracy,\n",
    "        'depth': tree_depth,\n",
    "        'nodes': node_count,\n",
    "        'training_time': training_time,\n",
    "        'predictions': y_pred\n",
    "    })\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Tree depth: {tree_depth}\")\n",
    "    print(f\"Number of nodes: {node_count}\")\n",
    "    print(f\"Training time: {training_time:.4f}s\")\n",
    "\n",
    "# Compare with sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "sklearn_dt = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=42)\n",
    "sklearn_dt.fit(X_train, y_train)\n",
    "sklearn_pred = sklearn_dt.predict(X_test)\n",
    "sklearn_accuracy = accuracy_score(y_test, sklearn_pred)\n",
    "\n",
    "print(f\"\\nðŸ” Comparison with Scikit-learn:\")\n",
    "print(f\"Custom Decision Tree (Gini): {dt_results[0]['accuracy']:.4f}\")\n",
    "print(f\"Sklearn Decision Tree (Gini): {sklearn_accuracy:.4f}\")\n",
    "print(f\"Difference: {abs(dt_results[0]['accuracy'] - sklearn_accuracy):.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Decision Tree tests completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Decision Tree results\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Accuracy comparison\n",
    "plt.subplot(2, 3, 1)\n",
    "criteria = [r['criterion'] for r in dt_results]\n",
    "accuracies = [r['accuracy'] for r in dt_results]\n",
    "bars = plt.bar(criteria, accuracies, alpha=0.7, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy by Splitting Criterion')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add sklearn comparison\n",
    "plt.axhline(y=sklearn_accuracy, color='red', linestyle='--', label=f'Sklearn: {sklearn_accuracy:.3f}')\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 2: Tree complexity comparison\n",
    "plt.subplot(2, 3, 2)\n",
    "depths = [r['depth'] for r in dt_results]\n",
    "nodes = [r['nodes'] for r in dt_results]\n",
    "\n",
    "x_pos = np.arange(len(criteria))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x_pos - width/2, depths, width, label='Tree Depth', alpha=0.7, color='orange')\n",
    "plt.bar(x_pos + width/2, nodes, width, label='Node Count', alpha=0.7, color='purple')\n",
    "\n",
    "plt.xlabel('Criterion')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Tree Complexity Comparison')\n",
    "plt.xticks(x_pos, criteria)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Feature importance visualization (for Gini criterion)\n",
    "plt.subplot(2, 3, 3)\n",
    "# Simple feature importance based on how often each feature is used for splitting\n",
    "feature_names = iris.feature_names\n",
    "feature_usage = np.zeros(len(feature_names))\n",
    "\n",
    "# This is a simplified version - in practice, you'd traverse the tree\n",
    "# and calculate importance based on impurity decrease\n",
    "# For demonstration, we'll show feature variance as a proxy\n",
    "feature_importance = np.var(X_train, axis=0)\n",
    "feature_importance = feature_importance / np.sum(feature_importance)  # Normalize\n",
    "\n",
    "bars = plt.bar(range(len(feature_names)), feature_importance, alpha=0.7, color='green')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Relative Importance')\n",
    "plt.title('Feature Importance (Variance-based)')\n",
    "plt.xticks(range(len(feature_names)), [name[:10] + '...' if len(name) > 10 else name \n",
    "                                      for name in feature_names], rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Confusion Matrix for best model\n",
    "plt.subplot(2, 3, 4)\n",
    "best_result = max(dt_results, key=lambda x: x['accuracy'])\n",
    "cm = confusion_matrix(y_test, best_result['predictions'])\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title(f'Confusion Matrix ({best_result[\"criterion\"].title()} Criterion)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Plot 5: Training time comparison\n",
    "plt.subplot(2, 3, 5)\n",
    "training_times = [r['training_time'] for r in dt_results]\n",
    "bars = plt.bar(criteria, training_times, alpha=0.7, color='coral')\n",
    "plt.ylabel('Training Time (s)')\n",
    "plt.title('Training Time by Criterion')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, time_val in zip(bars, training_times):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.05,\n",
    "             f'{time_val:.4f}s', ha='center', va='bottom')\n",
    "\n",
    "# Plot 6: Decision boundary visualization (using first two features)\n",
    "plt.subplot(2, 3, 6)\n",
    "# Use only first two features for visualization\n",
    "X_2d = X_train[:, :2]\n",
    "y_2d = y_train\n",
    "\n",
    "# Train a 2D decision tree\n",
    "dt_2d = DecisionTreeFromScratch(criterion='gini', max_depth=3)\n",
    "dt_2d.fit(X_2d, y_2d)\n",
    "\n",
    "# Create mesh for decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict on mesh\n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = dt_2d.predict(mesh_points)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.6, cmap='viridis')\n",
    "scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_2d, alpha=0.8, edgecolors='black')\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "plt.title('Decision Boundary (First 2 Features)')\n",
    "plt.colorbar(scatter)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results table\n",
    "print(\"ðŸ“Š Decision Tree Performance Summary:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Criterion':<15} {'Accuracy':<10} {'Depth':<6} {'Nodes':<6} {'Time (s)':<10}\")\n",
    "print(\"=\" * 70)\n",
    "for result in dt_results:\n",
    "    print(f\"{result['criterion']:<15} {result['accuracy']:<10.4f} \"\n",
    "          f\"{result['depth']:<6} {result['nodes']:<6} {result['training_time']:<10.4f}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Sklearn (Gini)':<15} {sklearn_accuracy:<10.4f} {'N/A':<6} {'N/A':<6} {'N/A':<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Problem 4: Model Evaluation and Cross-Validation\n",
    "\n",
    "**Problem Statement**: Implement comprehensive model evaluation techniques from scratch.\n",
    "\n",
    "**Requirements**:\n",
    "- K-fold cross-validation\n",
    "- Stratified sampling for imbalanced datasets\n",
    "- Bootstrap sampling and confidence intervals\n",
    "- Multiple evaluation metrics\n",
    "- Learning curves and validation curves\n",
    "\n",
    "**Key Concepts**: Bias-variance tradeoff, overfitting detection, model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive model evaluation toolkit.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def k_fold_cross_validation(X, y, model, k=5, random_state=None):\n",
    "        \"\"\"Perform k-fold cross-validation.\"\"\"\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        fold_size = n_samples // k\n",
    "        scores = []\n",
    "        predictions_all = np.zeros(n_samples)\n",
    "        \n",
    "        for fold in range(k):\n",
    "            # Define test indices for this fold\n",
    "            start_idx = fold * fold_size\n",
    "            end_idx = start_idx + fold_size if fold < k - 1 else n_samples\n",
    "            \n",
    "            test_indices = indices[start_idx:end_idx]\n",
    "            train_indices = np.concatenate([indices[:start_idx], indices[end_idx:]])\n",
    "            \n",
    "            # Split data\n",
    "            X_train_fold = X[train_indices]\n",
    "            y_train_fold = y[train_indices]\n",
    "            X_test_fold = X[test_indices]\n",
    "            y_test_fold = y[test_indices]\n",
    "            \n",
    "            # Train and predict\n",
    "            model_copy = type(model)(**model.__dict__)\n",
    "            model_copy.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = model_copy.predict(X_test_fold)\n",
    "            \n",
    "            # Store predictions\n",
    "            predictions_all[test_indices] = y_pred_fold\n",
    "            \n",
    "            # Calculate accuracy for this fold\n",
    "            fold_accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "            scores.append(fold_accuracy)\n",
    "        \n",
    "        return scores, predictions_all\n",
    "    \n",
    "    @staticmethod\n",
    "    def stratified_k_fold(X, y, model, k=5, random_state=None):\n",
    "        \"\"\"Perform stratified k-fold cross-validation.\"\"\"\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        \n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        n_samples = len(X)\n",
    "        scores = []\n",
    "        predictions_all = np.zeros(n_samples)\n",
    "        \n",
    "        # Create stratified folds\n",
    "        folds = [[] for _ in range(k)]\n",
    "        \n",
    "        for class_label in unique_classes:\n",
    "            class_indices = np.where(y == class_label)[0]\n",
    "            np.random.shuffle(class_indices)\n",
    "            \n",
    "            # Distribute class samples across folds\n",
    "            for i, idx in enumerate(class_indices):\n",
    "                folds[i % k].append(idx)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        for fold in range(k):\n",
    "            test_indices = np.array(folds[fold])\n",
    "            train_indices = np.concatenate([folds[i] for i in range(k) if i != fold])\n",
    "            \n",
    "            # Split data\n",
    "            X_train_fold = X[train_indices]\n",
    "            y_train_fold = y[train_indices]\n",
    "            X_test_fold = X[test_indices]\n",
    "            y_test_fold = y[test_indices]\n",
    "            \n",
    "            # Train and predict\n",
    "            model_copy = type(model)(**model.__dict__)\n",
    "            model_copy.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = model_copy.predict(X_test_fold)\n",
    "            \n",
    "            # Store predictions\n",
    "            predictions_all[test_indices] = y_pred_fold\n",
    "            \n",
    "            # Calculate accuracy for this fold\n",
    "            fold_accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "            scores.append(fold_accuracy)\n",
    "        \n",
    "        return scores, predictions_all\n",
    "    \n",
    "    @staticmethod\n",
    "    def bootstrap_evaluation(X, y, model, n_bootstrap=100, random_state=None):\n",
    "        \"\"\"Perform bootstrap evaluation for confidence intervals.\"\"\"\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        scores = []\n",
    "        \n",
    "        for i in range(n_bootstrap):\n",
    "            # Bootstrap sample\n",
    "            bootstrap_indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            out_of_bag_indices = np.setdiff1d(np.arange(n_samples), bootstrap_indices)\n",
    "            \n",
    "            if len(out_of_bag_indices) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Train on bootstrap sample\n",
    "            X_bootstrap = X[bootstrap_indices]\n",
    "            y_bootstrap = y[bootstrap_indices]\n",
    "            \n",
    "            # Test on out-of-bag samples\n",
    "            X_oob = X[out_of_bag_indices]\n",
    "            y_oob = y[out_of_bag_indices]\n",
    "            \n",
    "            # Train and predict\n",
    "            model_copy = type(model)(**model.__dict__)\n",
    "            model_copy.fit(X_bootstrap, y_bootstrap)\n",
    "            y_pred_oob = model_copy.predict(X_oob)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            oob_accuracy = accuracy_score(y_oob, y_pred_oob)\n",
    "            scores.append(oob_accuracy)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    @staticmethod\n",
    "    def learning_curve(X, y, model, train_sizes, cv=5, random_state=None):\n",
    "        \"\"\"Generate learning curve data.\"\"\"\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        \n",
    "        train_scores = []\n",
    "        val_scores = []\n",
    "        \n",
    "        for train_size in train_sizes:\n",
    "            # Limit training data\n",
    "            n_train = int(train_size * len(X))\n",
    "            indices = np.random.choice(len(X), n_train, replace=False)\n",
    "            X_subset = X[indices]\n",
    "            y_subset = y[indices]\n",
    "            \n",
    "            # Perform cross-validation on subset\n",
    "            cv_scores, _ = ModelEvaluator.k_fold_cross_validation(\n",
    "                X_subset, y_subset, model, k=cv, random_state=random_state\n",
    "            )\n",
    "            \n",
    "            # Also calculate training score\n",
    "            model_copy = type(model)(**model.__dict__)\n",
    "            model_copy.fit(X_subset, y_subset)\n",
    "            train_pred = model_copy.predict(X_subset)\n",
    "            train_score = accuracy_score(y_subset, train_pred)\n",
    "            \n",
    "            train_scores.append(train_score)\n",
    "            val_scores.append(np.mean(cv_scores))\n",
    "        \n",
    "        return train_sizes, train_scores, val_scores\n",
    "\n",
    "# Test Model Evaluation techniques\n",
    "print(\"ðŸ§ª Testing Model Evaluation Techniques:\")\n",
    "\n",
    "# Load Wine dataset for evaluation\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_wine_scaled = scaler.fit_transform(X_wine)\n",
    "\n",
    "# Create a logistic regression model for testing\n",
    "eval_model = LogisticRegressionFromScratch(\n",
    "    learning_rate=0.01, max_iters=500, regularization='l2', reg_strength=0.01\n",
    ")\n",
    "\n",
    "# 1. K-Fold Cross-Validation\n",
    "print(\"\\n=== K-Fold Cross-Validation ===\")\n",
    "cv_scores, cv_predictions = ModelEvaluator.k_fold_cross_validation(\n",
    "    X_wine_scaled, y_wine, eval_model, k=5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"CV Scores: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "print(f\"Mean CV Score: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores) * 2:.4f})\")\n",
    "\n",
    "# 2. Stratified K-Fold Cross-Validation\n",
    "print(\"\\n=== Stratified K-Fold Cross-Validation ===\")\n",
    "stratified_scores, stratified_predictions = ModelEvaluator.stratified_k_fold(\n",
    "    X_wine_scaled, y_wine, eval_model, k=5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Stratified CV Scores: {[f'{score:.4f}' for score in stratified_scores]}\")\n",
    "print(f\"Mean Stratified CV Score: {np.mean(stratified_scores):.4f} (+/- {np.std(stratified_scores) * 2:.4f})\")\n",
    "\n",
    "# 3. Bootstrap Evaluation\n",
    "print(\"\\n=== Bootstrap Evaluation ===\")\n",
    "bootstrap_scores = ModelEvaluator.bootstrap_evaluation(\n",
    "    X_wine_scaled, y_wine, eval_model, n_bootstrap=50, random_state=42\n",
    ")\n",
    "\n",
    "bootstrap_mean = np.mean(bootstrap_scores)\n",
    "bootstrap_ci = np.percentile(bootstrap_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"Bootstrap Mean Score: {bootstrap_mean:.4f}\")\n",
    "print(f\"95% Confidence Interval: [{bootstrap_ci[0]:.4f}, {bootstrap_ci[1]:.4f}]\")\n",
    "\n",
    "# 4. Learning Curves\n",
    "print(\"\\n=== Learning Curves ===\")\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "lc_train_sizes, lc_train_scores, lc_val_scores = ModelEvaluator.learning_curve(\n",
    "    X_wine_scaled, y_wine, eval_model, train_sizes, cv=3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Learning curve computed for {len(train_sizes)} training sizes\")\n",
    "print(f\"Final training score: {lc_train_scores[-1]:.4f}\")\n",
    "print(f\"Final validation score: {lc_val_scores[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Model evaluation tests completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Model Evaluation results\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Cross-validation scores comparison\n",
    "plt.subplot(3, 3, 1)\n",
    "methods = ['K-Fold CV', 'Stratified CV']\n",
    "mean_scores = [np.mean(cv_scores), np.mean(stratified_scores)]\n",
    "std_scores = [np.std(cv_scores), np.std(stratified_scores)]\n",
    "\n",
    "bars = plt.bar(methods, mean_scores, yerr=std_scores, alpha=0.7, capsize=5)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Cross-Validation Comparison')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, score in zip(bars, mean_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 2: Individual fold scores\n",
    "plt.subplot(3, 3, 2)\n",
    "folds = range(1, 6)\n",
    "plt.plot(folds, cv_scores, 'o-', label='K-Fold CV', alpha=0.8, linewidth=2)\n",
    "plt.plot(folds, stratified_scores, 's-', label='Stratified CV', alpha=0.8, linewidth=2)\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Fold-wise Performance')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Bootstrap score distribution\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.hist(bootstrap_scores, bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "plt.axvline(bootstrap_mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {bootstrap_mean:.3f}')\n",
    "plt.axvline(bootstrap_ci[0], color='orange', linestyle='--', alpha=0.7, label='95% CI')\n",
    "plt.axvline(bootstrap_ci[1], color='orange', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Bootstrap Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Bootstrap Score Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Learning curves\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.plot(lc_train_sizes, lc_train_scores, 'o-', label='Training Score', alpha=0.8, linewidth=2)\n",
    "plt.plot(lc_train_sizes, lc_val_scores, 's-', label='Validation Score', alpha=0.8, linewidth=2)\n",
    "plt.xlabel('Training Set Size (fraction)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Fill area between curves to show gap\n",
    "plt.fill_between(lc_train_sizes, lc_train_scores, lc_val_scores, alpha=0.1, color='red')\n",
    "\n",
    "# Plot 5: Confusion matrix for cross-validation predictions\n",
    "plt.subplot(3, 3, 5)\n",
    "cm_cv = confusion_matrix(y_wine, cv_predictions.astype(int))\n",
    "sns.heatmap(cm_cv, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=wine.target_names, yticklabels=wine.target_names)\n",
    "plt.title('Confusion Matrix (K-Fold CV)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Plot 6: Class distribution in dataset\n",
    "plt.subplot(3, 3, 6)\n",
    "unique_classes, class_counts = np.unique(y_wine, return_counts=True)\n",
    "bars = plt.bar(wine.target_names, class_counts, alpha=0.7, color=['red', 'green', 'blue'])\n",
    "plt.ylabel('Sample Count')\n",
    "plt.title('Class Distribution in Wine Dataset')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, count in zip(bars, class_counts):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "             str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 7: Model performance metrics\n",
    "plt.subplot(3, 3, 7)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Calculate detailed metrics for CV predictions\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_wine, cv_predictions.astype(int), average=None\n",
    ")\n",
    "\n",
    "x_pos = np.arange(len(wine.target_names))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x_pos - width, precision, width, label='Precision', alpha=0.7)\n",
    "plt.bar(x_pos, recall, width, label='Recall', alpha=0.7)\n",
    "plt.bar(x_pos + width, f1, width, label='F1-Score', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Per-Class Performance Metrics')\n",
    "plt.xticks(x_pos, wine.target_names, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 8: Bias-Variance analysis (simplified)\n",
    "plt.subplot(3, 3, 8)\n",
    "# Show training vs validation gap as proxy for bias-variance\n",
    "training_gap = np.array(lc_train_scores) - np.array(lc_val_scores)\n",
    "plt.plot(lc_train_sizes, training_gap, 'o-', color='red', alpha=0.8, linewidth=2)\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Training Set Size (fraction)')\n",
    "plt.ylabel('Training - Validation Gap')\n",
    "plt.title('Bias-Variance Indicator')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add interpretation text\n",
    "if training_gap[-1] > 0.1:\n",
    "    plt.text(0.5, max(training_gap) * 0.8, 'High Variance\\n(Overfitting)', \n",
    "             ha='center', va='center', bbox=dict(boxstyle='round', facecolor='red', alpha=0.3))\n",
    "else:\n",
    "    plt.text(0.5, max(training_gap) * 0.8, 'Good Balance', \n",
    "             ha='center', va='center', bbox=dict(boxstyle='round', facecolor='green', alpha=0.3))\n",
    "\n",
    "# Plot 9: Statistical significance test\n",
    "plt.subplot(3, 3, 9)\n",
    "from scipy import stats\n",
    "\n",
    "# Compare K-Fold vs Stratified CV using paired t-test\n",
    "t_stat, p_value = stats.ttest_rel(cv_scores, stratified_scores)\n",
    "\n",
    "# Create comparison visualization\n",
    "methods = ['K-Fold CV', 'Stratified CV']\n",
    "all_scores = [cv_scores, stratified_scores]\n",
    "\n",
    "positions = [1, 2]\n",
    "box_plot = plt.boxplot(all_scores, positions=positions, labels=methods, patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "colors = ['lightblue', 'lightgreen']\n",
    "for patch, color in zip(box_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Statistical Comparison\\n(p-value: {p_value:.4f})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add significance indicator\n",
    "if p_value < 0.05:\n",
    "    plt.text(1.5, max(np.concatenate(all_scores)) * 1.05, 'Significant Difference', \n",
    "             ha='center', va='center', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "else:\n",
    "    plt.text(1.5, max(np.concatenate(all_scores)) * 1.05, 'No Significant Difference', \n",
    "             ha='center', va='center', bbox=dict(boxstyle='round', facecolor='gray', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comprehensive evaluation summary\n",
    "print(\"\\nðŸ“Š Comprehensive Model Evaluation Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset: Wine Classification ({len(X_wine)} samples, {X_wine.shape[1]} features)\")\n",
    "print(f\"Classes: {len(wine.target_names)} ({', '.join(wine.target_names)})\")\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"  K-Fold CV (5-fold):        {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")\n",
    "print(f\"  Stratified CV (5-fold):    {np.mean(stratified_scores):.4f} Â± {np.std(stratified_scores):.4f}\")\n",
    "print(f\"  Bootstrap (50 samples):    {bootstrap_mean:.4f} [CI: {bootstrap_ci[0]:.4f}, {bootstrap_ci[1]:.4f}]\")\n",
    "print(f\"\\nLearning Curve Analysis:\")\n",
    "print(f\"  Final Training Score:      {lc_train_scores[-1]:.4f}\")\n",
    "print(f\"  Final Validation Score:    {lc_val_scores[-1]:.4f}\")\n",
    "print(f\"  Training-Validation Gap:   {lc_train_scores[-1] - lc_val_scores[-1]:.4f}\")\n",
    "print(f\"\\nStatistical Test:\")\n",
    "print(f\"  K-Fold vs Stratified t-test: t={t_stat:.4f}, p={p_value:.4f}\")\n",
    "print(f\"  Significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸƒâ€â™‚ï¸ Practice Problems\n",
    "\n",
    "Let's practice some additional problems that test understanding of ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 5: Ensemble Methods - Random Forest from Scratch\n",
    "class RandomForestFromScratch:\n",
    "    \"\"\"Random Forest implementation using our Decision Trees.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=10, max_features='sqrt', max_depth=None, \n",
    "                 min_samples_split=2, bootstrap=True, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.bootstrap = bootstrap\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        \n",
    "    def _get_max_features(self, n_features):\n",
    "        \"\"\"Calculate number of features to consider.\"\"\"\n",
    "        if self.max_features == 'sqrt':\n",
    "            return int(np.sqrt(n_features))\n",
    "        elif self.max_features == 'log2':\n",
    "            return int(np.log2(n_features))\n",
    "        elif isinstance(self.max_features, int):\n",
    "            return min(self.max_features, n_features)\n",
    "        elif isinstance(self.max_features, float):\n",
    "            return int(self.max_features * n_features)\n",
    "        else:\n",
    "            return n_features\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the random forest.\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        max_features = self._get_max_features(n_features)\n",
    "        \n",
    "        self.trees = []\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Create decision tree\n",
    "            tree = DecisionTreeFromScratch(\n",
    "                criterion='gini',\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                max_features=max_features\n",
    "            )\n",
    "            \n",
    "            # Bootstrap sampling\n",
    "            if self.bootstrap:\n",
    "                indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "                X_bootstrap = X[indices]\n",
    "                y_bootstrap = y[indices]\n",
    "            else:\n",
    "                X_bootstrap = X\n",
    "                y_bootstrap = y\n",
    "            \n",
    "            # Train tree\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using majority voting.\"\"\"\n",
    "        # Get predictions from all trees\n",
    "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        \n",
    "        # Majority voting\n",
    "        predictions = []\n",
    "        for i in range(X.shape[0]):\n",
    "            votes = tree_predictions[:, i]\n",
    "            prediction = np.argmax(np.bincount(votes))\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities.\"\"\"\n",
    "        # Get predictions from all trees\n",
    "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        \n",
    "        # Calculate probabilities based on votes\n",
    "        n_classes = len(np.unique(tree_predictions))\n",
    "        probabilities = []\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            votes = tree_predictions[:, i]\n",
    "            class_counts = np.bincount(votes, minlength=n_classes)\n",
    "            class_probs = class_counts / len(self.trees)\n",
    "            probabilities.append(class_probs)\n",
    "        \n",
    "        return np.array(probabilities)\n",
    "\n",
    "# Test Random Forest\n",
    "print(\"ðŸ§ª Testing Random Forest Implementation:\")\n",
    "\n",
    "# Use Iris dataset\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Test our Random Forest\n",
    "rf_custom = RandomForestFromScratch(\n",
    "    n_estimators=20, max_features='sqrt', max_depth=5, random_state=42\n",
    ")\n",
    "rf_custom.fit(X_train_iris, y_train_iris)\n",
    "rf_predictions = rf_custom.predict(X_test_iris)\n",
    "rf_probabilities = rf_custom.predict_proba(X_test_iris)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test_iris, rf_predictions)\n",
    "\n",
    "# Compare with sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_sklearn = RandomForestClassifier(n_estimators=20, max_features='sqrt', \n",
    "                                   max_depth=5, random_state=42)\n",
    "rf_sklearn.fit(X_train_iris, y_train_iris)\n",
    "rf_sklearn_pred = rf_sklearn.predict(X_test_iris)\n",
    "rf_sklearn_accuracy = accuracy_score(y_test_iris, rf_sklearn_pred)\n",
    "\n",
    "print(f\"Custom Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Sklearn Random Forest Accuracy: {rf_sklearn_accuracy:.4f}\")\n",
    "print(f\"Difference: {abs(rf_accuracy - rf_sklearn_accuracy):.4f}\")\n",
    "\n",
    "# Test individual vs ensemble performance\n",
    "print(f\"\\nðŸŒ³ Individual Tree vs Forest Comparison:\")\n",
    "\n",
    "# Single decision tree\n",
    "single_tree = DecisionTreeFromScratch(criterion='gini', max_depth=5)\n",
    "single_tree.fit(X_train_iris, y_train_iris)\n",
    "single_tree_pred = single_tree.predict(X_test_iris)\n",
    "single_tree_accuracy = accuracy_score(y_test_iris, single_tree_pred)\n",
    "\n",
    "print(f\"Single Decision Tree Accuracy: {single_tree_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Improvement: {rf_accuracy - single_tree_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Random Forest test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 6: Gradient Boosting (simplified version)\n",
    "class GradientBoostingFromScratch:\n",
    "    \"\"\"Simplified Gradient Boosting implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "        self.initial_prediction = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train gradient boosting model.\"\"\"\n",
    "        # For binary classification, convert to {-1, 1}\n",
    "        y_transformed = 2 * y - 1\n",
    "        \n",
    "        # Initial prediction (mean)\n",
    "        self.initial_prediction = np.mean(y_transformed)\n",
    "        \n",
    "        # Initialize predictions\n",
    "        predictions = np.full(len(y), self.initial_prediction)\n",
    "        \n",
    "        self.models = []\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Calculate residuals (negative gradient)\n",
    "            residuals = y_transformed - predictions\n",
    "            \n",
    "            # Fit a decision tree to residuals\n",
    "            tree = DecisionTreeFromScratch(\n",
    "                criterion='gini', \n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=2\n",
    "            )\n",
    "            \n",
    "            # Convert residuals to binary classification problem\n",
    "            # (simplified: use sign of residuals)\n",
    "            residual_classes = (residuals > 0).astype(int)\n",
    "            \n",
    "            # Skip if all residuals have same sign\n",
    "            if len(np.unique(residual_classes)) == 1:\n",
    "                break\n",
    "            \n",
    "            tree.fit(X, residual_classes)\n",
    "            self.models.append(tree)\n",
    "            \n",
    "            # Update predictions\n",
    "            tree_predictions = tree.predict(X)\n",
    "            # Convert back to {-1, 1}\n",
    "            tree_predictions = 2 * tree_predictions - 1\n",
    "            predictions += self.learning_rate * tree_predictions\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        predictions = np.full(X.shape[0], self.initial_prediction)\n",
    "        \n",
    "        for model in self.models:\n",
    "            tree_pred = model.predict(X)\n",
    "            tree_pred = 2 * tree_pred - 1  # Convert to {-1, 1}\n",
    "            predictions += self.learning_rate * tree_pred\n",
    "        \n",
    "        # Convert back to {0, 1}\n",
    "        return (predictions > 0).astype(int)\n",
    "\n",
    "# Test Gradient Boosting (simplified)\n",
    "print(\"ðŸ§ª Testing Simplified Gradient Boosting:\")\n",
    "\n",
    "# Use binary classification subset of Iris\n",
    "binary_mask = y_iris != 2  # Remove class 2 to make it binary\n",
    "X_binary = X_iris[binary_mask]\n",
    "y_binary = y_iris[binary_mask]\n",
    "\n",
    "X_train_gb, X_test_gb, y_train_gb, y_test_gb = train_test_split(\n",
    "    X_binary, y_binary, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Test our Gradient Boosting\n",
    "gb_custom = GradientBoostingFromScratch(\n",
    "    n_estimators=50, learning_rate=0.1, max_depth=3\n",
    ")\n",
    "gb_custom.fit(X_train_gb, y_train_gb)\n",
    "gb_predictions = gb_custom.predict(X_test_gb)\n",
    "\n",
    "gb_accuracy = accuracy_score(y_test_gb, gb_predictions)\n",
    "\n",
    "print(f\"Custom Gradient Boosting Accuracy: {gb_accuracy:.4f}\")\n",
    "print(f\"Number of weak learners used: {len(gb_custom.models)}\")\n",
    "\n",
    "# Compare with single tree\n",
    "single_tree_gb = DecisionTreeFromScratch(criterion='gini', max_depth=3)\n",
    "single_tree_gb.fit(X_train_gb, y_train_gb)\n",
    "single_pred_gb = single_tree_gb.predict(X_test_gb)\n",
    "single_accuracy_gb = accuracy_score(y_test_gb, single_pred_gb)\n",
    "\n",
    "print(f\"Single Tree Accuracy: {single_accuracy_gb:.4f}\")\n",
    "print(f\"Gradient Boosting Improvement: {gb_accuracy - single_accuracy_gb:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Gradient Boosting test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Interview Tips\n",
    "\n",
    "### ðŸŽ¯ Scikit-Learn Algorithm Fundamentals\n",
    "1. **Understand the math** - Know the underlying mathematics, not just the API\n",
    "2. **Know when to use each algorithm** - Understand strengths and weaknesses\n",
    "3. **Implement from scratch** - Shows deep understanding of algorithms\n",
    "4. **Compare with sklearn** - Validate your implementation\n",
    "5. **Handle edge cases** - Empty clusters, convergence, numerical stability\n",
    "\n",
    "### ðŸ¤– Algorithm Selection Guide\n",
    "- **K-Means**: When you need fast clustering with known number of clusters\n",
    "- **Logistic Regression**: Linear decision boundaries, interpretable results\n",
    "- **Decision Trees**: Non-linear patterns, feature interactions, interpretability\n",
    "- **Random Forest**: Reduces overfitting, handles missing values well\n",
    "- **Gradient Boosting**: High accuracy, but prone to overfitting\n",
    "\n",
    "### âš¡ Performance Considerations\n",
    "- **Time Complexity**: Know Big O notation for each algorithm\n",
    "- **Space Complexity**: Understand memory requirements\n",
    "- **Scalability**: How algorithms perform with large datasets\n",
    "- **Convergence**: When and why algorithms might not converge\n",
    "\n",
    "### ðŸ” Common Interview Questions\n",
    "1. \"Implement K-means from scratch\"\n",
    "2. \"Explain the difference between bagging and boosting\"\n",
    "3. \"How would you handle missing values in decision trees?\"\n",
    "4. \"What's the difference between L1 and L2 regularization?\"\n",
    "5. \"How do you choose the optimal number of clusters?\"\n",
    "\n",
    "### ðŸ“Š Model Evaluation Best Practices\n",
    "- **Cross-validation**: Always use proper validation techniques\n",
    "- **Stratified sampling**: For imbalanced datasets\n",
    "- **Multiple metrics**: Don't rely on accuracy alone\n",
    "- **Statistical significance**: Use confidence intervals and hypothesis testing\n",
    "- **Learning curves**: Diagnose bias-variance tradeoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "âœ… **K-Means Clustering** - Lloyd's algorithm, K-means++, elbow method  \n",
    "âœ… **Logistic Regression** - Gradient descent, regularization, multiple solvers  \n",
    "âœ… **Decision Trees** - Information gain, splitting criteria, pruning  \n",
    "âœ… **Model Evaluation** - Cross-validation, bootstrap, learning curves  \n",
    "âœ… **Random Forest** - Bootstrap aggregating, feature randomness  \n",
    "âœ… **Gradient Boosting** - Sequential learning, weak learners  \n",
    "\n",
    "### ðŸš€ Next Steps\n",
    "1. Practice implementing these algorithms from memory\n",
    "2. Try different datasets and compare performance\n",
    "3. Move on to neural network implementations\n",
    "4. Study advanced ensemble methods (XGBoost, LightGBM)\n",
    "\n",
    "### ðŸ“š Additional Practice\n",
    "- Implement support vector machines (SVM)\n",
    "- Create a complete ML pipeline with preprocessing\n",
    "- Build ensemble methods (voting, stacking)\n",
    "- Implement feature selection algorithms\n",
    "\n",
    "### ðŸ”‘ Key Takeaways for Interviews\n",
    "- **Mathematical Foundation**: Understand the underlying math\n",
    "- **Implementation Skills**: Can code algorithms from scratch\n",
    "- **Practical Knowledge**: Know when and how to use each algorithm\n",
    "- **Evaluation Expertise**: Proper model validation and selection\n",
    "- **Problem-Solving**: Handle edge cases and numerical issues\n",
    "\n",
    "**Ready to tackle deep learning next! ðŸ§ **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}